# ShadowHound + DIMOS Quick Start

**5-Minute Guide to Getting Started**

## üìã Prerequisites

- ‚úÖ Devcontainer running (ROS2 Humble)
- ‚úÖ ROBOT_IP environment variable set
- ‚úÖ OPENAI_API_KEY configured (for agents)

## üöÄ Quick Setup

### 1. Add DIMOS to Workspace (First Time)

```bash
# Create dependencies file
cat > shadowhound.repos << 'EOF'
repositories:
  dimos-unitree:
    type: git
    url: https://github.com/dimensionalOS/dimos-unitree.git
    version: main
  go2_ros2_sdk:
    type: git
    url: https://github.com/dimensionalOS/go2_ros2_sdk.git
    version: prod
EOF

# Import repositories
vcs import src < shadowhound.repos

# Install DIMOS Python package
pip3 install -e src/dimos-unitree

# Install ROS dependencies
rosdep install --from-paths src --ignore-src -y

# Build workspace
colcon build --symlink-install
source install/setup.bash
```

### 2. Test DIMOS Integration

```python
# In Python REPL or script
from dimos.robot.unitree import UnitreeGo2, UnitreeROSControl

# Mock robot (no hardware needed)
robot = UnitreeGo2(
    ros_control=UnitreeROSControl(mock_connection=True),
    disable_video_stream=True
)

print("‚úÖ DIMOS integration working!")
```

### 3. Run DIMOS Examples

```bash
# Navigate to DIMOS tests
cd src/dimos-unitree/tests

# Test basic robot control (mock mode)
python3 test_robot.py

# Test agent with FastAPI interface
# (requires OPENAI_API_KEY)
python3 test_unitree_agent_queries_fastapi.py
```

## ü§ñ Using DIMOS with Real Robot

```bash
# Set environment
export ROBOT_IP=192.168.1.103
export CONN_TYPE=webrtc
export OPENAI_API_KEY=sk-...

# Run DIMOS robot test
cd src/dimos-unitree/tests
python3 run_go2_ros.py
```

## üìù Creating a Custom ShadowHound Skill

```python
# File: src/shadowhound_skills/shadowhound_skills/patrol.py

from dimos.skills.skills import AbstractRobotSkill
from pydantic import Field

class PatrolArea(AbstractRobotSkill):
    """Patrol predefined waypoints."""
    
    name: str = "PatrolArea"
    description: str = "Patrol an area visiting waypoints in sequence"
    
    waypoints: list[tuple[float, float]] = Field(
        description="List of (x, y) waypoints"
    )
    
    def __call__(self, **kwargs) -> dict:
        """Execute patrol."""
        waypoints = kwargs.get('waypoints', self.waypoints)
        
        for i, (x, y) in enumerate(waypoints):
            # Use DIMOS navigation
            result = self._robot.skill_library.execute(
                "NavigateToGoal",
                x=x, y=y, theta=0.0
            )
            
            if not result.get('success'):
                return {
                    'success': False,
                    'error': f'Failed at waypoint {i}'
                }
        
        return {
            'success': True,
            'data': {'waypoints_visited': len(waypoints)}
        }
```

## üß™ Testing Custom Skill

```python
# File: test_patrol.py

from dimos.robot.unitree import UnitreeGo2, UnitreeROSControl
from shadowhound_skills import PatrolArea

# Initialize robot
robot = UnitreeGo2(
    ros_control=UnitreeROSControl(mock_connection=True),
    disable_video_stream=True
)

# Add custom skill
robot_skills = robot.get_skills()
robot_skills.add(PatrolArea)
robot_skills.create_instance("PatrolArea", robot=robot)

# Execute
result = robot_skills.execute(
    "PatrolArea",
    waypoints=[(1.0, 1.0), (2.0, 1.0), (2.0, 2.0), (1.0, 2.0)]
)

print(result)
```

## ü§ñ Using with Agent

```python
from dimos.agents import OpenAIAgent

# Robot already has skills library
agent = OpenAIAgent(
    dev_name="ShadowHoundAgent",
    tools=robot_skills.get_tools(),  # Auto-generates tool definitions
    model="gpt-4-turbo"
)

# Agent can now call skills
response = agent.query("Patrol the perimeter")
print(response)
```

## üìö Common DIMOS Patterns

### Robot Control
```python
# Direct control
robot.move(distance=1.0, speed=0.5)
robot.rotate(angle=1.57)  # 90 degrees
robot.webrtc_req(api_id=1006)  # RecoveryStand

# Get state
position, rotation = robot.get_pose()
```

### Available DIMOS Skills
```python
from dimos.skills.navigation import NavigateToGoal, NavigateWithText, GetPose
from dimos.skills.visual_navigation_skills import FollowHuman
from dimos.skills import KillSkill, Speak

# Add to robot
robot_skills = robot.get_skills()
robot_skills.add(NavigateToGoal)
robot_skills.add(Speak)

# Execute
robot_skills.execute("NavigateToGoal", x=2.0, y=1.0, theta=0.0)
robot_skills.execute("Speak", text="Mission complete")
```

### Video Streams (RxPY)
```python
# Get camera stream
video_stream = robot.get_ros_video_stream(fps=10)

# Subscribe to frames
def on_frame(frame):
    print(f"Got frame: {frame.shape}")

video_stream.subscribe(on_frame)
```

## üîß Troubleshooting

### DIMOS Not Found
```bash
# Make sure it's installed
pip3 list | grep dimos

# If not, install it
pip3 install -e src/dimos-unitree
```

### Can't Connect to Robot
```bash
# Check environment variables
echo $ROBOT_IP
echo $CONN_TYPE

# Verify robot is on network
ping $ROBOT_IP

# Check ROS2 topics
ros2 topic list
```

### Import Errors
```bash
# Source workspace
source install/setup.bash

# Check Python path
python3 -c "import sys; print('\n'.join(sys.path))"
```

## üìñ Learn More

- **Full Architecture**: `docs/project.md`
- **Integration Plan**: `docs/DIMOS_INTEGRATION.md`
- **DIMOS Examples**: `src/dimos-unitree/tests/`
- **DIMOS Docs**: https://github.com/dimensionalOS/dimos-unitree

## üéØ Next Steps

1. ‚úÖ Complete DIMOS integration (Phase 0)
2. ‚è≠Ô∏è Implement first custom skill (PatrolArea)
3. ‚è≠Ô∏è Test on mock robot
4. ‚è≠Ô∏è Test on real hardware
5. ‚è≠Ô∏è Build mission agent

---

**Questions?** Check `docs/project.md` for detailed architecture and patterns.
