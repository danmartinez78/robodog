# ============================================================================
# ShadowHound Environment Configuration
# ============================================================================
#
# This file contains all environment variables used by the ShadowHound
# autonomous robot system. Copy this file to `.env` and fill in your values.
#
# Usage:
#   1. Copy this file: cp .env.example .env
#   2. Edit .env with your specific values
#   3. The .env file is loaded automatically by DIMOS and ROS2
#   4. Never commit .env (it's in .gitignore)
#
# ============================================================================

# ----------------------------------------------------------------------------
# OpenAI Configuration (REQUIRED for cloud agent)
# ----------------------------------------------------------------------------

# OpenAI API Key - Required for ChatGPT/GPT-4 integration
# Used by: DIMOS OpenAIAgent for mission planning and natural language processing
# Get your key from: https://platform.openai.com/api-keys
# Default: None (will cause errors if cloud backend is used)
# Optional: Yes, if using local models only
OPENAI_API_KEY=sk-proj-your-api-key-here

# OpenAI Organization ID (optional)
# Used by: OpenAI client for organization-specific billing/tracking
# Get from: https://platform.openai.com/account/organization
# Default: None (uses default organization)
# Optional: Yes
# OPENAI_ORG_ID=org-your-org-id-here


# ----------------------------------------------------------------------------
# Robot Network Configuration
# ----------------------------------------------------------------------------

# Robot IP Address
# Used by: go2_ros2_sdk for direct communication with Unitree Go2
# Default: 192.168.1.103 (Unitree Go2 default ethernet IP)
# Optional: No (required for real robot connection)
# Note: Use this for ethernet connection. For WiFi, typically 192.168.12.1
GO2_IP=192.168.1.103

# Robot Control Interface
# Used by: go2_ros2_sdk to choose communication method
# Options: "ethernet" | "wifi" | "webrtc"
# Default: ethernet
# Optional: Yes
# GO2_INTERFACE=ethernet

# WebRTC Signaling Server (for WebRTC connection mode)
# Used by: go2_webrtc_connect for remote robot control
# Default: None (not needed for ethernet/wifi)
# Optional: Yes (only needed if using WebRTC)
# WEBRTC_SIGNALING_SERVER=wss://your-signaling-server.com


# ----------------------------------------------------------------------------
# ROS2 Configuration
# ----------------------------------------------------------------------------

# ROS Domain ID
# Used by: ROS2 DDS for network isolation
# Default: 0
# Optional: Yes
# Range: 0-101 (avoid 0 if multiple ROS systems on same network)
# Note: All ROS2 nodes must use the same domain ID to communicate
ROS_DOMAIN_ID=42

# ROS Middleware Implementation
# Used by: ROS2 for DDS communication
# Options: "rmw_fastrtps_cpp" | "rmw_cyclonedds_cpp"
# Default: rmw_fastrtps_cpp
# Optional: Yes
# Note: CycloneDDS often has better performance
RMW_IMPLEMENTATION=rmw_cyclonedds_cpp

# ROS Log Level
# Used by: ROS2 logging system
# Options: DEBUG | INFO | WARN | ERROR | FATAL
# Default: INFO
# Optional: Yes
# RCUTILS_LOGGING_LEVEL=INFO


# ----------------------------------------------------------------------------
# Agent Configuration
# ----------------------------------------------------------------------------

# Agent Backend
# Used by: mission_agent.py to select LLM provider
# Options: "cloud" | "local"
# Default: cloud
# Optional: Yes
# Note: "cloud" uses OpenAI, "local" uses local models (requires additional setup)
AGENT_BACKEND=cloud

# Use Planning Agent (vs. basic OpenAI Agent)
# Used by: mission_agent.py to enable advanced planning capabilities
# Options: "true" | "false"
# Default: false
# Optional: Yes
# Note: PlanningAgent creates step-by-step plans before execution
USE_PLANNING_AGENT=false

# Mock Robot Mode
# Used by: mission_agent.py for testing without hardware
# Options: "true" | "false"
# Default: false
# Optional: Yes
# Note: Useful for development and testing agent logic without robot
MOCK_ROBOT=false


# ----------------------------------------------------------------------------
# Web Interface Configuration
# ----------------------------------------------------------------------------

# Enable Web Dashboard
# Used by: mission_agent.py to start/stop web server
# Options: "true" | "false"
# Default: true
# Optional: Yes
# Note: Disable for headless deployments or production security
ENABLE_WEB_INTERFACE=true

# Web Interface Port
# Used by: web_interface.py for HTTP/WebSocket server
# Default: 8080
# Optional: Yes
# Note: Change if port 8080 is already in use
WEB_PORT=8080

# Web Interface Host
# Used by: web_interface.py for binding address
# Default: 0.0.0.0 (all interfaces)
# Optional: Yes
# Note: Use 127.0.0.1 to restrict to localhost only
# WEB_HOST=0.0.0.0


# ----------------------------------------------------------------------------
# RAG / Semantic Memory Configuration
# ----------------------------------------------------------------------------

# Use Local Embeddings (vs. OpenAI embeddings)
# Used by: RAG memory initialization for vector embeddings
# Options: "true" | "false"
# Default: false
# Optional: Yes
# Note: "true" = free local embeddings, "false" = OpenAI embeddings (costs $)
USE_LOCAL_EMBEDDINGS=false

# Semantic Memory Collection Name
# Used by: ChromaDB for vector database collection naming
# Default: shadowhound_missions
# Optional: Yes
# CHROMA_COLLECTION_NAME=shadowhound_missions

# RAG Query Count
# Used by: OpenAIAgent to determine how many documents to retrieve
# Default: 4
# Optional: Yes
# Range: 1-20 (higher = more context but more tokens)
# RAG_QUERY_N=4

# RAG Similarity Threshold
# Used by: OpenAIAgent to filter retrieved documents by relevance
# Default: 0.45
# Optional: Yes
# Range: 0.0-1.0 (higher = stricter matching)
# RAG_SIMILARITY_THRESHOLD=0.45


# ----------------------------------------------------------------------------
# OpenAI Model Configuration
# ----------------------------------------------------------------------------

# OpenAI Model Name
# Used by: OpenAIAgent for ChatGPT model selection
# Options: "gpt-4o" | "gpt-4" | "gpt-4-turbo" | "gpt-3.5-turbo"
# Default: gpt-4o
# Optional: Yes
# Note: gpt-4o is fastest and supports vision, gpt-4 is most capable
OPENAI_MODEL=gpt-4o

# OpenAI Embedding Model (for RAG)
# Used by: OpenAISemanticMemory for document embeddings
# Options: "text-embedding-3-large" | "text-embedding-3-small" | "text-embedding-ada-002"
# Default: text-embedding-3-large
# Optional: Yes
# Note: 3-large is best quality, 3-small is cheaper
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# OpenAI Embedding Dimensions (for 3-small or 3-large)
# Used by: OpenAISemanticMemory for vector dimensions
# Default: 1024 (for 3-large), 1536 (for 3-small)
# Optional: Yes
# Range: 256-3072 for 3-large, 256-1536 for 3-small
# OPENAI_EMBEDDING_DIMENSIONS=1024

# Max Input Tokens per Request
# Used by: OpenAIAgent for prompt size limiting
# Default: 128000 (gpt-4o max)
# Optional: Yes
# Note: Adjust based on model limits
# MAX_INPUT_TOKENS=128000

# Max Output Tokens per Request
# Used by: OpenAIAgent for response size limiting
# Default: 16384
# Optional: Yes
# MAX_OUTPUT_TOKENS=16384


# ----------------------------------------------------------------------------
# Local LLM Configuration (if using local backend)
# ----------------------------------------------------------------------------

# Local LLM Server URL
# Used by: OpenAI client when using local inference server
# Default: http://localhost:8000 (typical LM Studio / vLLM port)
# Optional: Yes (only needed if AGENT_BACKEND=local)
# Note: Must be OpenAI-compatible API (LM Studio, vLLM, llama.cpp, etc.)
# LOCAL_LLM_URL=http://localhost:8000/v1

# Local LLM Model Name
# Used by: OpenAI client for local model selection
# Default: None (depends on local server)
# Optional: Yes (only needed if AGENT_BACKEND=local)
# LOCAL_LLM_MODEL=llama-3-70b-instruct


# ----------------------------------------------------------------------------
# Logging and Debugging
# ----------------------------------------------------------------------------

# Python Log Level
# Used by: Python logging module
# Options: DEBUG | INFO | WARNING | ERROR | CRITICAL
# Default: INFO
# Optional: Yes
# LOG_LEVEL=INFO

# DIMOS Debug Mode
# Used by: DIMOS framework for verbose logging
# Options: "true" | "false"
# Default: false
# Optional: Yes
# DIMOS_DEBUG=false

# Agent Output Directory
# Used by: DIMOS agent for saving logs, frames, and results
# Default: ./assets/agent
# Optional: Yes
# AGENT_OUTPUT_DIR=./assets/agent


# ----------------------------------------------------------------------------
# Performance Tuning
# ----------------------------------------------------------------------------

# Thread Pool Size
# Used by: DIMOS for parallel processing
# Default: 4
# Optional: Yes
# Range: 1-32 (higher = more parallel processing)
# THREAD_POOL_SIZE=4

# Process All Inputs (vs. skip when busy)
# Used by: OpenAIAgent for input processing strategy
# Options: "true" | "false"
# Default: false (for video streams), true (for text queries)
# Optional: Yes
# Note: "true" queues all inputs, "false" drops inputs when agent is busy
# PROCESS_ALL_INPUTS=false


# ----------------------------------------------------------------------------
# Development and Testing
# ----------------------------------------------------------------------------

# Environment Name
# Used by: Application logic for environment-specific behavior
# Options: "development" | "staging" | "production"
# Default: development
# Optional: Yes
ENVIRONMENT=development

# Enable Test Mode
# Used by: Application for test-specific behavior
# Options: "true" | "false"
# Default: false
# Optional: Yes
# TEST_MODE=false

# Disable GPU (force CPU for testing)
# Used by: PyTorch and other GPU libraries
# Options: "true" | "false"
# Default: false
# Optional: Yes
# Note: Useful for testing on machines without GPU
# CUDA_VISIBLE_DEVICES=-1


# ----------------------------------------------------------------------------
# Security (Production)
# ----------------------------------------------------------------------------

# API Rate Limiting
# Used by: Web interface for rate limiting protection
# Default: None (no rate limiting)
# Optional: Yes
# Format: requests per minute
# API_RATE_LIMIT=60

# Web Interface Authentication Token
# Used by: Web interface for basic authentication
# Default: None (no authentication)
# Optional: Yes
# WARNING: The default web interface has NO authentication!
# WEB_AUTH_TOKEN=your-secret-token-here

# Allowed Origins (CORS)
# Used by: Web interface for CORS policy
# Default: * (all origins)
# Optional: Yes
# Format: comma-separated list of origins
# ALLOWED_ORIGINS=http://localhost:3000,https://yourdomain.com


# ============================================================================
# End of Configuration
# ============================================================================
#
# Quick Start:
#   1. Minimum required: OPENAI_API_KEY and GO2_IP
#   2. Recommended: Set ROS_DOMAIN_ID to avoid conflicts
#   3. Optional: Configure web port, RAG settings, model selection
#
# Common Configurations:
#
#   Development (with mock robot):
#     OPENAI_API_KEY=sk-...
#     MOCK_ROBOT=true
#     ROS_DOMAIN_ID=42
#
#   Production (real robot, no web UI):
#     OPENAI_API_KEY=sk-...
#     GO2_IP=192.168.1.103
#     ENABLE_WEB_INTERFACE=false
#     ROS_DOMAIN_ID=42
#
#   Cost-optimized (local embeddings, GPT-3.5):
#     OPENAI_API_KEY=sk-...
#     OPENAI_MODEL=gpt-3.5-turbo
#     USE_LOCAL_EMBEDDINGS=true
#     GO2_IP=192.168.1.103
#
#   Advanced (planning agent with RAG):
#     OPENAI_API_KEY=sk-...
#     USE_PLANNING_AGENT=true
#     USE_LOCAL_EMBEDDINGS=false
#     RAG_QUERY_N=5
#     GO2_IP=192.168.1.103
#
# Troubleshooting:
#   - If agent doesn't start: Check OPENAI_API_KEY is valid
#   - If can't connect to robot: Verify GO2_IP and network
#   - If port conflict: Change WEB_PORT to different value
#   - If ROS nodes can't communicate: Check ROS_DOMAIN_ID matches
#   - If embeddings fail: Set USE_LOCAL_EMBEDDINGS=true
#
# Documentation:
#   - Main README: /workspaces/shadowhound/README.md
#   - ChatGPT Integration: docs/CHATGPT_INTEGRATION.md
#   - RAG Integration: docs/RAG_INTEGRATION.md
#   - Web Interface: src/shadowhound_mission_agent/WEB_INTERFACE.md
#
# ============================================================================
